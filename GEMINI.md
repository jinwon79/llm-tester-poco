# LLM Tester POC (Proof of Concept)

> LLM Model Performance Comparison & System Prompt A/B Testing Platform

---

## Core Principles

### 1. Objective-Driven
Focused on precise evaluation of LLM capabilities and prompt engineering efficiency.

### 2. SoR (Single Source of Truth) Priority
1st: Codebase
2nd: GEMINI.md
3rd: README.md

### 3. Cross-Platform Compatibility
Ensure compatibility between Windows (Dev) and Linux (Prod).
*   **Path Handling**: Use `/` or `pathlib`.
*   **Encoding**: UTF-8 for all text files.
*   **Line Endings**: LF (`\n`).

---

## Tech Stack

| Item | Value |
|------|-------|
| Framework | Next.js 16.1.1 (App Router) |
| UI Library | React 19.2.3, Tailwind CSS v4 |
| Language | TypeScript |
| Engine | Node.js (v20+) |
| Package Manager | npm |

---

## Project Structure

```
F:\llm-tester-poco
├── app/                # Next.js App Router (Pages & API)
├── components/         # React Components
├── lib/                # Utility Functions & SDK Wrappers
├── public/             # Static Assets
├── results/            # Evaluation Results (Markdown/JSON)
└── .env.local          # Environment Variables (API Keys)
```

## Development Workflow

### 1. Prerequisites
*   Node.js v20+ installed.
*   API Keys for Google, Anthropic, OpenAI.

### 2. Setup
```bash
# Clone/Navigate
cd F:\llm-tester-poco

# Install Dependencies
npm install

# Environment Setup
# Create .env.local and add detailed keys:
# GOOGLE_GENERATIVE_AI_API_KEY=...
# ANTHROPIC_API_KEY=...
# OPENAI_API_KEY=...
```

### 3. Run
```bash
# Development Server
npm run dev
# Access at http://localhost:3000

# Production Build
npm run build
npm start
```

---

## Features

1.  **Model Evaluation (`/model-eval`)**: concurrent testing of Gemini, Claude, GPT.
2.  **Prompt A/B Testing (`/prompt-eval`)**: Compare system prompts.
3.  **Result Management**: Auto-save to `results/`.

---

**Generated by**: Antigravity
**Template Version**: 1.0.0
